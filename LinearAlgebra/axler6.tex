\documentclass[11pt]{article}
\usepackage[T1]{fontenc}
\usepackage{geometry, changepage, hyperref}
\usepackage{amsmath, amssymb, amsthm, bm}
\usepackage{physics, esint}

\hypersetup{colorlinks=true, linkcolor=blue, urlcolor=cyan}
\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt}

\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\uvec}[1]{\mathop{} \!\hat{\textbf{#1}}}
\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\tensor}[1]{\mathsf{#1}}
\newcommand{\nll}{\operatorname{null}}
\newcommand{\range}{\operatorname{range}}

\newcommand{\conjugate}[1]{\overline{#1}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem*{theorem*}{Theorem}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{claim*}{Claim}

\title{Axler: Inner Product Spaces}
\author{James Pagan}
\date{January 2023}

% --------------------------------------------- %

\begin{document}

\maketitle
\tableofcontents
\newpage

% --------------------------------------------- %

\section{Inner Products and Norms}

% --------------------------------------------- %

\subsection{Inner Products}

An \textbf{inner product} over a complex (or real) vector space $V$ is a map $\ev{\cdot, \cdot} : V \times V \to \mathbb{C}$ that satisfies the following properties for all $\vec{u}, \vec{v}, \vec{w} \in \vec{V}$ and $\lambda \in \mathbb{C}$:
\begin{enumerate}
	\item \textbf{Conjugate Symmetry}: $\ev{\vec{v}, \vec{w}} = \conjugate{\ev{\vec{w}, \vec{v}}}$
	\item \textbf{Positive-Definiteness}: $\ev{\vec{v}, \vec{v}} \ge 0$, with equality if and only if $\vec{v} = \vec{0}$.
	\item \textbf{Additivity in First Argument}: $\ev{\vec{u} + \vec{v}, \vec{w}}$ = $\ev{\vec{u}, \vec{w}} + \ev{\vec{v}, \vec{w}}$.
	\item \textbf{Homogenity in First Argument}: $\ev{\lambda \vec{v}, \vec{w}}$ = $\lambda \ev{\vec{v}, \vec{w}}$.
\end{enumerate}
As $z = \conjugate{z}$ if and only if $z$ is real, $(1)$ implies that $\ev{\vec{v}, \vec{v}} \in \mathbb{R}$; hence, $(3)$ is a valid condition. An \textbf{inner product space} is a vector space $V$ over $\mathbb{R}$ or $\mathbb{C}$. We will exclusively prove theorems about complex vector spaces; proofs for inner product spaces over $\mathbb{R}$ are identical.

\begin{theorem}
	Suppose $V$ is an inner product space. Then the following five properties hold: for each $\vec{u}, \vec{v}, \vec{w} \in V$ and $\lambda \in \mathbb{C}$:
	\begin{enumerate}
		\item The function $f(\vec{v}) = \ev{\vec{v}, \vec{w}}$ is a linear map from $V$ to $\mathbb{C}$.
		\item $\ev{\vec{0}, \vec{v}} = \ev{\vec{v}, \vec{0}} = 0$.
		\item $\ev{\vec{u}, \vec{v} + \vec{w}} = \ev{\vec{u}, \vec{v}} + \ev{\vec{u}, \vec{w}}$.
		\item $\ev{\vec{v}, \lambda \vec{w}} = \conjugate{\lambda} \ev{\vec{v}, \vec{w}}$
	\end{enumerate}
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		Let $\vec{u}$, $\vec{v}$, and $\vec{w}$ be arbitrary vectors of $V$ and let $\lambda$ be an arbitrary scalar of $\mathbb{C}$. For (1), note that
		\[
			f(\vec{u} + \vec{v}) = \ev{\vec{u} + \vec{v}, \vec{w}} = \ev{\vec{u}, \vec{w}} + \ev{\vec{v}, \vec{w}} = f(\vec{u}) + f(\vec{v})j
		\]
		and see that
		\[
			f(\lambda \vec{v}) = \ev{\lambda \vec{v}, \vec{w}} = \lambda \ev{\vec{v}, \vec{w}} = \lambda f(\vec{v});
		\]
		thus $f$ is linear. For (2), observe that
		\[
			\ev{\vec{0}, \vec{v}} = \ev{0 \vec{v}, \vec{v}} = 0 \ev{\vec{v}, \vec{v}} = 0.
		\]
		Similarly, $\ev{\vec{v}, \vec{0}} = \conjugate{\ev{\vec{0}, \vec{v}}} = \conjugate{0} = 0$. For (3), notice that
		\[
			\ev{\vec{u}, \vec{v} + \vec{w}} = \conjugate{\ev{\vec{v} + \vec{w}, \vec{u}}} = \conjugate{\ev{\vec{v}, \vec{u}} + \ev{\vec{w}, \vec{u}}} = \ev{\vec{u}, \vec{v}} + \ev{\vec{u}, \vec{w}}.
		\]
		Finally, we have that $\ev{\vec{v}, \lambda \vec{w}} = \conjugate{\ev{\lambda \vec{w}, \vec{v}}} = \conjugate{\lambda \ev{\vec{w}, \vec{v}}} = \conjugate{\lambda} \ev{\vec{v}, \vec{w}}$, yielding (4).
	\end{proof}
\end{adjustwidth}

% --------------------------------------------- %

\subsection{Norms}

The \textbf{norm} of a vector $\vec{v}$ in an inner product space $V$ is defined as
\[
	\norm{\vec{v}} = \sqrt{\ev{\vec{v}, \vec{v}}}.
\]
\begin{theorem}
	Suppose $V$ is an inner product space. Then the following properties hold for all $\vec{v} \in V$ and $\lambda \in \mathbb{C}$:
	\begin{itemize}
		\item $\norm{\vec{v}} = 0$ if and only if $\vec{v} = \vec{0}$.
		\item $\norm{\lambda \vec{v}} = \abs{\lambda} \norm{\vec{v}}$.
	\end{itemize}
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		$(1)$ follows from the fact that
		\begin{align*}
			\norm{\vec{v}} = 0 &\iff \sqrt{\ev{\vec{v}, \vec{v}}} = 0 \\
			&\iff \ev{\vec{v}, \vec{v}} = 0 \\
			&\iff \vec{v} = 0.
		\end{align*}
		For $(2)$, see that
		\[
			\norm{\lambda \vec{v}} = \sqrt{\ev{\lambda \vec{v}, \lambda \vec{v}}} = \sqrt{\lambda \conjugate{\lambda} \ev{\vec{v}, \vec{v}}} = \sqrt{\abs{\lambda}^{2} \ev{\vec{v}, \vec{v}}} = \abs{\lambda} \sqrt{\ev{\vec{v}, \vec{v}}} = \abs{\lambda} \norm{\vec{v}},
		\]
		as desired.
	\end{proof}
\end{adjustwidth}

Two vectors $\vec{v}$ and $\vec{w}$ in an inner product space $V$ are \textbf{orthogonal} if $\ev{\vec{v}, \vec{w}} = 0$. Clearly, every vector is orthogonal to $\vec{0}$ --- and the only vector orthogonal to itself is also $\vec{0}$.

\begin{theorem}
	Suppose $V$ is an inner product space. Then if $\vec{v}, \vec{w} \in V$ are orthogonal, then
	\[
		\norm{\vec{v} + \vec{w}}^{2} = \norm{\vec{v}}^{2} + \norm{\vec{w}}^{2}.
	\]
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		Suppose $\ev{\vec{v}, \vec{w}} = 0$. Then
		\begin{align*}
			\norm{\vec{v} + \vec{w}}^{2} &= \ev{\vec{v} + \vec{w}, \vec{v} + \vec{w}} \\
			&= \ev{\vec{v}, \vec{v}} + \ev{\vec{v}, \vec{w}} + \ev{\vec{w}, \vec{v}} + \ev{\vec{w}, \vec{w}} \\
			&= \ev{\vec{v}, \vec{v}} + \ev{\vec{w}, \vec{w}} \\
			&= \norm{\vec{v}}^{2} + \norm{\vec{w}}^{2}.
		\end{align*}
		This is like the Pythagorean Theorem for vectors.
	\end{proof}
\end{adjustwidth}

\begin{theorem}
	Suppose $\vec{v} \ne \vec{0}$ and $\vec{w}$ are vectors in an inner product space. Then setting $c = \frac{\ev{\vec{v}, \vec{w}}}{\norm{\vec{w}}^{2}}$ and $\vec{u} = \vec{v} - \frac{\ev{\vec{v}, \vec{w}}}{\norm{\vec{w}}^{2}} \vec{w}$ yields
	\[
		\vec{v} = c \vec{w} + \vec{u} \qquad \text{and} \qquad \ev{\vec{u}, \vec{w}} = 0.
	\]
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		The result is a mere computation. Clearly $\vec{v} = c \vec{w} + \vec{u}$; as for the orthogonality,
		\begin{align*}
			\ev{\vec{u}, \vec{w}} &= \ev{\vec{v} - \frac{\ev{\vec{v}, \vec{w}}}{\norm{\vec{w}}^{2}} \vec{w}, \vec{w}} \\
			&= \ev{\vec{v}, \vec{w}} - \ev{\frac{\ev{\vec{v}, \vec{w}}}{\norm{\vec{w}}^{2}} \vec{w}, \vec{w}} \\
			&= \ev{\vec{v}, \vec{w}} - \frac{\ev{\vec{v}, \vec{w}}}{\norm{\vec{w}}^{2}} \ev{\vec{w}, \vec{w}}\\ 
			&= \ev{\vec{v}, \vec{w}} - \frac{\ev{\vec{v}, \vec{w}}}{\norm{\vec{w}}^{2}} \norm{\vec{w}}^{2} \\
			&= \ev{\vec{v}, \vec{w}} - \ev{\vec{v}, \vec{w}} \\
			&= 0,
		\end{align*}
		as required. The vector $c \vec{w}$ is often denoted $\operatorname{Proj}_{\vec{v}}(\vec{w})$.
	\end{proof}
\end{adjustwidth}

\begin{theorem}
	Suppose $V$ is an inner product space. Then for all $\vec{v}, \vec{w} \in V$,
	\[
		\abs{\ev{\vec{v}, \vec{w}}} \le \norm{\vec{v}} \norm{\vec{w}},
	\]
	with equality if and if one of $\vec{v}, \vec{w}$ is a scalar multiple of the other. 
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		Enabled by Theorem 4, we consider the orthogonal decomposition below, defining $\vec{u}$ in the process:
		\[
			\vec{v} = \frac{\ev{\vec{v}, \vec{w}}}{\norm{\vec{w}}^{2}} \vec{w} + \vec{u}.
		\]
		For simplicity, let $\frac{\ev{\vec{v}, \vec{w}}}{\norm{\vec{w}}^{2}} = c$. Now $\ev{c \vec{w}, \vec{u}} = c \ev{\vec{w}, \vec{u}} = 0$, so by the Pythagorean Theorem,
		\begin{align*}
			\norm{\vec{v}}^{2} \norm{\vec{w}}^{2} &= \norm{c \vec{w} + \vec{u}}^{2}\norm{\vec{w}}^{2} \\
			&= (\abs{c}^{2} \norm{\vec{w}}^{2} + \norm{\vec{u}}^{2}) \vec{v}^{2} \\
			&= \left( \frac{\abs{\ev{\vec{v}, \vec{w}}}^{2}}{\norm{\vec{w}}^{4}} \norm{\vec{w}}^{2} + \norm{\vec{u}}^{2} \right) \norm{\vec{w}}^{2} \\
			&= \frac{\abs{\ev{\vec{v}, \vec{w}}}^{2}}{\norm{\vec{w}}^{2}} \norm{\vec{w}}^{2} + \norm{\vec{u}}^{2} \norm{\vec{w}}^{2} \\
			&= \abs{\ev{\vec{v}, \vec{w}}}^{2} + \norm{\vec{u}}^{2} \norm{\vec{w}}^{2} \\
			&\ge \abs{\ev{\vec{v}, \vec{w}}}^{2}.
		\end{align*} 
		We achieve equality at the last ste if $\vec{w} = \vec{0}$ or if $\vec{u} = \vec{0}$; that is, if there exists $c \in \mathbb{C}$ such that $\vec{v} = c \vec{w}$. In either case, $\vec{v}$ and $\vec{w}$ are scalar multiples of each other. This proves the Cauchy-Schwarz Inequality.
	\end{proof}
\end{adjustwidth}

\begin{theorem}
	Suppose $V$ is an inner product space and $\vec{v}, \vec{w} \in V$. Then
	\[
		\norm{\vec{v}} + \norm{\vec{w}} \ge \norm{\vec{v} + \vec{w}},
	\]
	with equality if and only if one of $\vec{v}, \vec{w}$ is a nonnegative real multiple of the other.
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		We have that
		\begin{align*}
			\norm{\vec{v}} + \norm{\vec{w}} &= \sqrt{\left( \norm{\vec{v}} + \norm{\vec{w}} \right)^{2}} \\
			&= \sqrt{\norm{\vec{v}}^{2} + 2 \norm{\vec{v}} \norm{\vec{w}} + \norm{\vec{w}}^{2}} \\
			&\ge \sqrt{\norm{\vec{v}}^{2} + 2 \abs{\ev{\vec{v}, \vec{w}}} + \norm{\vec{w}}^{2}} \\
			&\ge \sqrt{\norm{\vec{v}}^{2} + 2 \Re \ev{\vec{v}, \vec{w}} + \norm{\vec{w}}^{2}} \\
			&= \sqrt{\norm{\vec{v}}^{2} + \ev{\vec{v}, \vec{w}} + \conjugate{\ev{\vec{v}, \vec{w}}} + \norm{\vec{w}}^{2}} \\
			&= \sqrt{\ev{\vec{v}, \vec{v}} + \ev{\vec{v}, \vec{w}} + \ev{\vec{w}, \vec{v}} + \ev{\vec{w}, \vec{w}}} \\
			&= \sqrt{\ev{\vec{v} + \vec{w}, \vec{v} + \vec{w}}} \\
			&= \sqrt{\norm{\vec{v} + \vec{w}}^{2}} \\
			&= \norm{\vec{v} + \vec{w}}^{2},
		\end{align*}
		as required. Equality holds in the first inequality if and only if one of $\vec{v}, \vec{w}$ is a scalar multiple of the other; if this is the case, then $\ev{\vec{v}, \vec{w}}$ is a scalar multiple of $\vec{v}, \vec{v}$. The second inequality holds if this scalar multiple is positive --- proving the Triangle Inequality.
	\end{proof}
\end{adjustwidth}

\begin{theorem}
		Suppose $V$ is an inner product space and $\vec{v}, \vec{w} \in V$. Then 
		\[
			\norm{\vec{v} + \vec{w}}^{2} + \norm{\vec{v} - \vec{w}}^{2} = 2 \left( \norm{\vec{v}}^{2} + \norm{\vec{w}}^{2} \right).
		\]
		This is called the Parallelogram Equality.
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		We have that
		\begin{align*}
			\norm{\vec{v} + \vec{w}}^{2} + \norm{\vec{v} - \vec{w}}^{2} &= \ev{\vec{v} + \vec{w}, \vec{v} + \vec{w}} + \ev{\vec{v} - \vec{w}, \vec{v} - \vec{w}} \\ 
			&= \ev{\vec{v}, \vec{v}} + \ev{\vec{v}, \vec{w}} + \ev{\vec{w}, \vec{v}} + \ev{\vec{w}, \vec{w}} \\
			& \quad + \ev{\vec{v}, \vec{v}} - \ev{\vec{v}, \vec{w}} - \ev{\vec{w}, \vec{v}} + \ev{\vec{w}, \vec{w}} \\
			&= 2 \left( \ev{\vec{v}, \vec{v}} + \ev{\vec{w}, \vec{w}} \right) \\
			&= 2 \left( \norm{\vec{v}}^{2} + \norm{\vec{w}}^{2} \right),
		\end{align*}
		as required.
	\end{proof}
\end{adjustwidth}

I'm gonna be honest, I think notes like these would look much prettier if I hand-wrote them. Admittedly, it's less efficent.

\newpage

% --------------------------------------------- %

\section{Orthonormal Bases}

% --------------------------------------------- %

A list of vectors is called \textbf{orthonormal} if each vector in the list has norm $1$ and is orthogonal to all the other vectors in the list. In other words, a list of vectors $\vec{e}_{1}, \ldots, \vec{e}_{m} \in V$ is orthonormal if
\[
	\ev{\vec{e}_{j}, \vec{e}_{k}} =
	\begin{cases}
		1 & \text{if } j = k, \\
		0 & \text{if } j \ne k
	\end{cases}
\]
for all $j, k \in \{ 1, \ldots, m \}$.

\begin{theorem}
	Suppose $\vec{e}_{1}, \ldots, \vec{e}_{n} \in V$ is an orthonormal list. Then for all $\lambda_{1}, \ldots, \lambda_{m} \in \mathbb{C}$,
	\[
		\norm{\lambda_{1} \vec{e}_{1} + \cdots + \lambda_{m} \vec{e}_{m}}^{2} = \abs{\lambda_{1}}^{2} + \cdots + \abs{\lambda_{m}}^{2}.
	\]
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		Realize that $\ev{\lambda_{j} \vec{e}_{j}, \lambda_{k} \vec{e}_{k}} = \lambda_{j} \conjugate{\lambda_{k}} \ev{\vec{e}_{j}, \vec{e}_{k}} = 0$ for all $j, k \in \{ 1, \ldots, m \}$ and $j \ne k$. Then by the Pythagorean Theorem,
		\[
			\norm{\lambda_{1} \vec{e}_{1} + \cdots + \lambda_{m} \vec{e}_{m}}^{2} = \norm{\lambda_{1} \vec{e}_{1}}^{2} + \cdots + \norm{\lambda_{m} \vec{e}_{m}}^{2} = \abs{\lambda_{1}}^{2} + \cdots + \abs{\lambda_{m}}^{2},
		\]
		as desired.
	\end{proof}
\end{adjustwidth}

\begin{theorem}
	Every orthonormal list of vectors is linearly independent.
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		Let $\vec{e}_{1}, \ldots, \vec{e}_{m} \in V$ be an orthonormal list of vectors. Suppose for contradiction that there exist $\lambda_{1}, \ldots, \lambda_{m} \in \mathbb{C}$, not all zero, such that
		\[
			\lambda_{1} \vec{e}_{1} + \cdots + \lambda_{m} \vec{e}_{m} = \vec{0}.
		\]
		Then by Theorem 8, 
		\[
			0 = \norm{\lambda_{1} \vec{e}_{1} + \cdots + \lambda_{m} \vec{e}_{m}}^{2} = \abs{\lambda_{1}}^{2} + \cdots + \abs{\lambda_{m}}^{2}.
		\]
		We conclude that all the $\lambda_{1}, \ldots, \lambda_{m}$ are zero, which yields the desired contradiction.
	\end{proof}
\end{adjustwidth}

\begin{theorem}
	Suppose $\vec{e}_{1}, \ldots, \vec{e}_{m} \in V$ is an orthonormal list of vectors. Then for all $\vec{v} \in V$,
	\[
		\abs{\ev{\vec{v}, \vec{e}_{1}}}^{2} + \cdots + \abs{\ev{\vec{v}, \vec{e}_{m}}}^{2} \le \norm{\vec{v}}^{2}.
	\]
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		I am not sure, but I would like to think of a proof myself.
	\end{proof}
\end{adjustwidth}

An \textbf{orthonormal basis} of $V$ is an orthonormal list of vectors in $V$ that is a basis of $V$. If $V$ is finite dimensional, then any orthonormal list of length $\dim V$ is an orthonrmal basis.

\newpage

Each $\ev{\vec{v}, \vec{e}_{i}}$ for $i \in \{ 1, \ldots, n \}$ equals the $i$-th coordinate of $\vec{v}$ as written as a lienar combination of $\vec{e}_{1}, \ldots, \vec{e}_{n}$ --- an idea expanded upon in the following theorem:

\begin{theorem}
	Suppose $\vec{e}_{1}, \ldots, \vec{e}_{n} \in V$ is an orthonormal basis of $V$ and $\vec{v}, \vec{w} \in V$. Then the following three identities hold:
	\begin{enumerate}
		\item $\vec{v} = \ev{\vec{v}, \vec{e}_{1}} \vec{e}_{1} + \cdots + \ev{\vec{v}, \vec{e}_{n}} \vec{e}_{n}$.
		\item $\norm{\vec{v}}^{2} = \abs{\ev{\vec{v}, \vec{e}_{1}}}^{2} + \cdots + \abs{\ev{\vec{v}, \vec{e}_{n}}}^{2}$.
		\item $\ev{\vec{v}, \vec{w}} = \ev{\vec{v}, \vec{e}_{1}} \conjugate{\ev{\vec{w}, \vec{e_{1}}}} + \cdots + \ev{\vec{v}, \vec{e}_{n}} \conjugate{\ev{\vec{w}, \vec{e_{n}}}}$
	\end{enumerate}
\end{theorem}
\begin{adjustwidth}{1cm}{}
	\begin{proof}
		Define $v_{1}, \ldots, v_{n} \in \mathbb{C}$ and $w_{1}, \ldots, w_{n} \in \mathbb{C}$ such that
		\[
			v_{1} \vec{e}_{1} + \cdots + v_{n} \vec{e}_{n} = \vec{v} \quad \text{and} \quad w_{1} \vec{e}_{1} + \cdots + w_{n} \vec{e}_{n} = \vec{w}.
		\]
		For $(1)$, realize that for all $i \in \{ 1, \ldots, n \}$, 
		\[
			\ev{\vec{v}, \vec{e}_{i}} = \ev{v_{1} \vec{e}_{1} + \cdots + v_{n} \vec{e}_{n}, \vec{e}_{i}} + v_{1} \ev{\vec{e}_{1}, \vec{e}_{i}} + \cdots + v_{n} \ev{\vec{e}_{n}, \vec{e}_{i}} = v_{i}.
		\]
		Therefore, 
		\[
			\ev{\vec{v}, \vec{e}_{1}} \vec{e}_{1} + \cdots + \ev{\vec{v}, \vec{e}_{n}} \vec{e}_{n} = v_{1} \vec{e}_{1} + \cdots v_{n} \vec{e}_{n} = \vec{v}.
		\]
		$(2)$ follows immmediately from Theorem 8. For $(3)$, we may use the formula of $(1)$ to derive that
		\begin{align*}
			\ev{\vec{v}, \vec{w}} &= \ev{v_{1} \vec{e}_{1} + \cdots + v_{n} \vec{e_{n}}, \vec{w}} \\
			&= v_{1} \ev{\vec{e}_{1}, \vec{w}} + \cdots + v_{n} \ev{\vec{e}_{n}, \vec{w}} \\
			&= v_{1} \conjugate{\ev{\vec{w}, \vec{e}_{1}}} + \cdots + v_{n} \conjugate{\ev{\vec{w}, \vec{e}_{n}}} \\
			&= \ev{\vec{v}, \vec{e}_{1}} \conjugate{\ev{\vec{w}, \vec{e_{1}}}} + \cdots + \ev{\vec{v}, \vec{e}_{n}} \conjugate{\ev{\vec{w}, \vec{e_{n}}}},
		\end{align*}
		as required.	
	\end{proof}
\end{adjustwidth}

% --------------------------------------------- %

\end{document}
